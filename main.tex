\documentclass{beamer}

%
% Choose how your presentation looks.
%
% For more themes, color themes and font themes, see:
% http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html
%
\mode<presentation>
{
  \usetheme{default}      % or try Darmstadt, Madrid, Warsaw, ...
  \usecolortheme{default} % or try albatross, beaver, crane, ...
  \usefonttheme{default}  % or try serif, structurebold, ...
  \setbeamertemplate{navigation symbols}{}
  \setbeamertemplate{caption}[numbered]
  \setbeamertemplate{footline}[page number]
  \setbeamercolor{frametitle}{fg=white}
  \setbeamercolor{footline}{fg=black}
} 

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{tikz}
\usepackage{listings}
\usepackage{courier}

\xdefinecolor{darkblue}{rgb}{0.1,0.1,0.7}
\xdefinecolor{dianablue}{rgb}{0.18,0.24,0.31}
\definecolor{commentgreen}{rgb}{0,0.6,0}
\definecolor{stringmauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{white},      % choose the background color
  basicstyle=\ttfamily\small,         % size of fonts used for the code
  breaklines=true,                    % automatic line breaking only at whitespace
  captionpos=b,                       % sets the caption-position to bottom
  commentstyle=\color{commentgreen},  % comment style
  escapeinside={\%*}{*)},             % if you want to add LaTeX within your code
  keywordstyle=\color{blue},          % keyword style
  stringstyle=\color{stringmauve},    % string literal style
  showstringspaces=false,
  showlines=true
}

\lstdefinelanguage{scala}{
  morekeywords={abstract,case,catch,class,def,%
    do,else,extends,false,final,finally,%
    for,if,implicit,import,match,mixin,%
    new,null,object,override,package,%
    private,protected,requires,return,sealed,%
    super,this,throw,trait,true,try,%
    type,val,var,while,with,yield},
  otherkeywords={=>,<-,<\%,<:,>:,\#,@},
  sensitive=true,
  morecomment=[l]{//},
  morecomment=[n]{/*}{*/},
  morestring=[b]",
  morestring=[b]',
  morestring=[b]"""
}

\lstdefinelanguage{sql}{
  morekeywords={WITH,AS,SELECT,FROM,GROUP,BY,OVER,PARTITION,ORDER,DESC,FROM,ON,INNER,JOIN,AND,OR,WHERE},
  sensitive=false,
  morecomment=[l]{//},
  morecomment=[n]{/*}{*/},
  morestring=[b]",
  morestring=[b]',
  morestring=[b]"""
}

\title[2016-08-16-ROOT-to-Arrow]{High Energy Physics Analysis Software}
\author{Jim Pivarski}
\institute{Princeton University -- DIANA}
\date{August 16, 2016}

\begin{document}

\logo{\pgfputat{\pgfxy(0.11, 8)}{\pgfbox[right,base]{\tikz{\filldraw[fill=dianablue, draw=none] (0 cm, 0 cm) rectangle (50 cm, 1 cm);}}}\pgfputat{\pgfxy(0.11, -0.6)}{\pgfbox[right,base]{\tikz{\filldraw[fill=dianablue, draw=none] (0 cm, 0 cm) rectangle (50 cm, 1 cm);}\includegraphics[height=0.99 cm]{diana-hep-logo.png}\tikz{\filldraw[fill=dianablue, draw=none] (0 cm, 0 cm) rectangle (4.9 cm, 1 cm);}}}}

\begin{frame}
  \titlepage
\end{frame}

\logo{\pgfputat{\pgfxy(0.11, 8)}{\pgfbox[right,base]{\tikz{\filldraw[fill=dianablue, draw=none] (0 cm, 0 cm) rectangle (50 cm, 1 cm);}\includegraphics[height=1 cm]{diana-hep-logo.png}}}}

% Uncomment these lines for an automatically generated outline.
%\begin{frame}{Outline}
%  \tableofcontents
%\end{frame}

\begin{frame}{High energy physics (HEP) software}
\vspace{0.25 cm}

\begin{block}{Physicists have been writing their own software for generations}
\begin{description}
\item[1970's] HBOOK histogramming, MINUIT non-linear fitting.
\item[1980's] PAW analysis framework, plotting.
\item[1990's] ROOT C++ analysis framework, object persistence/file format, foundation for most collaboration infrastructures.
\item[2000's] Ecosystem built around ROOT, some high-level Python interfaces, but analysts have to rewrite for performance. Nearly all analysis code is imperative.
\end{description}
\end{block}

\begin{uncoverenv}<2->
\begin{block}{``Designed by physicists'' usually isn't a compliment}
\begin{itemize}
\item Custom solutions justified by the HEP problem being unique: no one else deals with such big datasets.
\item That's not really true.
\end{itemize}
\end{block}
\end{uncoverenv}
\end{frame}

\begin{frame}{DIANA-HEP}
\begin{itemize}\setlength{\itemsep}{0.5 cm}
\item NSF-funded program to modernize physics software \textcolor{gray}{(``Scientific Software Integration (SSI)'' for the ``Software Infrastructure for Sustained Innovation (SI)$^2$.'')}
\item Small group: 4 PI's, 12 computer scientists, machine learning experts and physicists.
\item Me: I'm a PhD physicist, helped to commission the LHC during 2006--2011 (just before the Higgs discovery), then spent 5 years as a data science consultant before DIANA-HEP.
\end{itemize}
\end{frame}

\begin{frame}{HEP interest in Big Data/Maching Learning}
\vspace{0.25 cm}
\begin{itemize}\setlength{\itemsep}{0.25 cm}
\item Bottom-up: several groups are independently looking into using software ``from industry'' for HEP analysis.
\item Not all students are going to stay in the field: many consider careers in data science.
\begin{itemize}
\item Deep familiarity with ROOT's quirks is not marketable.
\end{itemize}
\item Machine learning is now established in HEP for signal-background discrimination, gaining ground in particle identification.
\begin{itemize}
\item New techniques developing rapidly; we can't keep reimplementing them!
\end{itemize}
\item Interest in reducing software maintainance costs by using freely available analysis software, rather than our own.
\item It's probably better designed, too.
\end{itemize}
\end{frame}

\begin{frame}{Petabytes of data in ROOT format}
\vspace{0.25 cm}
\begin{itemize}\setlength{\itemsep}{0.1 cm}
\item ROOT file is a container, like HDF5, of any kind of objects, like Python's pickle.
\item C++ objects, not abstract data types:
\begin{itemize}
\item Serialization/deserialization code generated by C++ reflection: ROOT contains a compiler (recently LLVM, yay!).
\item ``StreamerInfo'' (schema) contained in ROOT file, so deserialization is possible without original header files.
\item Pointers and circular references are allowed.
\end{itemize}
\item Columnar storage: objects are split into leaves of the object graph and stored consecutively. Not all leaves must be read.
\item Designed as a mutable object database for non-consecutive reading/writing (rarely used that way, if ever).
\begin{itemize}
\item File-reading involves a {\it lot} of seeking.
\item XRootD: special transfer protocol to support this.
\end{itemize}
\item 1.2 implementations:
\begin{itemize}
\item ROOT itself.
\item FreeHEP: Java alternative to ROOT, discontinued in the early 2000's. Can't load complex objects.
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{ROOT data access outside of C++}
\begin{itemize}
\item Within the ROOT project

\begin{description}
\item[PyROOT] auto-generates proxies to view ROOT objects as Python; anything can be accessed (slowly).
\end{description}

\item Popular alternatives
\begin{description}
\item[RootPy] wrapper around PyROOT, ``more Pythonic.''
\item[root\_numpy] integrates with RootPy for fast ROOT-to- Numpy. Can't load complex objects.
\end{description}

\item My own projects
\begin{description}
\item[root2avro] inspects StreamerInfo to map complex objects onto Avro schemas; converts file to file.
\item[ScaROOT 1] same through the JNI to create objects in Scala.
\item[ScaROOT 2] uses an external process instead of the JNI.
\end{description}
\end{itemize}

All of the above run ROOT to read the file itself.

{\scriptsize (Hard to reimplement seeking logic, custom Streamers, and XRootD optimization.)}
\end{frame}

\begin{frame}{My interest in Arrow}
\vspace{0.4 cm}
\begin{block}{One data translation, many targets}
\begin{itemize}
\item Except for cross/circular references, Arrow type system is rich enough to represent ROOT data.
\item References can be managed manually with some lookup table.
\item Might even be more CPU-cache efficient for analysis.
\item Standardization gets data over the native/JVM hurdle.
\item Zero-copy to Pandas and machine learning libraries.
\end{itemize}
\end{block}

\begin{block}{Parquet may be a good alternative file format}
\begin{itemize}
\item Same rich type system for complex objects.
\item Columnar layout on disk for fast reading of partial objects.
\item Not a mutable object database, but that's not necessary.
\item Readable beyond the HEP community.
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{What I want to learn}
\vspace{0.5 cm}
Hooks and examples for getting started.

\vspace{1 cm}
Familiarity with maturity of the format, the code, the roadplan, expected level of integration into Parquet, Pandas, and Spark.
\begin{itemize}
\item approximately when?
\item complex objects or flat tables of primitives?
\item zero-copy?
\end{itemize}

\vspace{1 cm}
In what ways would we collaborate, and in what ways would our work be independent or derivative?
\end{frame}

\begin{frame}{}
\begin{center}
\Huge \textcolor{darkblue}{Different topic: HEP queries}
\end{center}
\end{frame}

\begin{frame}{Declarative languages}
\vspace{0.25 cm}
Data analysis frameworks outside of HEP use declarative queries:
\begin{itemize}
\item DataFrames (R, Pandas, SparkSQL): transformations and selections applied to each row of the table are actually computed column-wise for efficiency.
\item SQL: long history of abstraction between the expressions users type and how the backend optimizes it.
\end{itemize}

\vspace{0.5 cm}
Very little HEP analysis is performed this way: transformations and selections written as ``for'' loops with ``if'' statements can only be executed as written.

\vspace{0.25 cm}
Analysis code in Python has to get rewritten in C++ when it scales up.

\vspace{0.25 cm}
We stand to benefit from more abstraction.
\end{frame}

\begin{frame}{Problem of structure}

``Flat ntuples'' (DataFrames of primitive types) can be directly loaded into Pandas and analyzed as-is.

\vspace{0.5 cm}
However, HEP analyses often make use of hierarchical structure:
\begin{itemize}
\item Charged particle tracks are made up of detector ``hits.''
\item Calorimeter showers consist of clusters of energy deposits.
\item Hadrons, taus, and W/Z bosons decay before they can be detected; they're identified as a spray of decay products, known as ``jets.''
\item High-energy LHC analyses make use of subjets within jets.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Problem of structure}
\vspace{0.5 cm}
Queries like the following are not unusual:
\begin{enumerate}
\item ``momentum of the track with the most hits with theta between -2.4 and 2.4''
\item ``average charge of all hits with time in 0-10 ps on all tracks with momentum greater than 10 GeV/c''
\item ``weighted average theta of the two tracks with highest momentum''
\end{enumerate}

\scriptsize
\begin{verbatim}
event: struct
  |
  +--- missing energy: float
  +--- tracks: array of struct
         |
         +--- momentum: float
         +--- theta angle: float
         +--- hits: array of struct
                |
                +--- charge: float
                +--- time: float
                +--- ...
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Not too bad in a functional language}
\vspace{0.1 cm}
\begin{enumerate}
\item

\begin{lstlisting}[language=scala]
{event => event.tracks        // get tracks
  .filter(abs(_.theta) < 2.4) // in theta range
  .maxBy(_.hits.size)         // the most hits
  .momentum                   // return
}
\end{lstlisting}

\item

\begin{lstlisting}[language=scala]
{event => mean(
  event.tracks                // get tracks
   .filter(_.momentum > 10)   // cut tracks
   .flatMap(_.hits)           // explode
   .filter(_.time < 10)       // cut hits
   .map(_.charge)             // return charge
  )}      // send charges to the mean function
\end{lstlisting}

\item

\begin{lstlisting}[language=scala]
{event => val List(one, two) =  // unpack
  event.tracks                  // get tracks
   .sortBy(_.momentum)          // sort
   .take(2);                    // take two
 (one.theta*one.momentum + two.theta*two.momentum) / (one.momentum + two.momentum)}
\end{lstlisting}
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{But way too complicated in SQL}
\vspace{0.25 cm}
\begin{enumerate}
\item
\begin{lstlisting}[language=sql, basicstyle=\ttfamily\scriptsize]
 WITH hit_stats AS (
  SELECT hit.track_id, COUNT(*) AS hit_count FROM hit GROUP BY hit.track_id
 ),
 track_sorted AS (
    SELECT track.*, 
    ROW_NUMBER() OVER (
     PARTITION BY track.event_id
     ORDER BY hit_stats.hit_count DESC
    )
  track_ordinal FROM track 
    INNER JOIN hit_stats ON hit_stats.track_id = track.id
    WHERE track.theta > -2.4 AND track.theta < 2.4
 )

 SELECT * FROM event
   INNER JOIN track_sorted ON track_sorted.event_id = event.id

WHERE
  track_sorted.track_ordinal = 1
\end{lstlisting}
\end{enumerate}
(That was only the first example!)
\end{frame}

\begin{frame}{Extensions useful for HEP}
\vspace{0.25 cm}
\begin{itemize}
\item \textcolor{darkblue}{map/flatMap/filter/sort/min/max} over collections within a row (operating on an array of structs, not explicitly exploding/joining)
\item \textcolor{darkblue}{min/max} that return top-$N$ for fixed $N$
\item in-place functions for the above
\item \textcolor{darkblue}{join(list1, list2, \ldots)} or ``cartesian'' for the equivalent of a double-for loop
\item \textcolor{darkblue}{pairs(list1)} that only combines upper-triangular
\item \textcolor{darkblue}{bestMatch(list1, list2, objectiveFcn)} to find a bijection between list1 and list2 that minimizes objectiveFcn
\end{itemize}

\vspace{0.5 cm}
\textcolor{darkblue}{Does this sort of thing exist by another name?}

\vspace{0.5 cm}
\textcolor{darkblue}{If not, would it be useful for non-HEP data analysis?}
\end{frame}

\end{document}
